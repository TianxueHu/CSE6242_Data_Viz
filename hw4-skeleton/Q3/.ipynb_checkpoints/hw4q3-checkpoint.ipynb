{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB0vv4pBcWu9"
   },
   "source": [
    "# Q3 Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GalZFbfhcWvA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8CbpTPx9rKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thu82\n"
     ]
    }
   ],
   "source": [
    "# Change to your GA Tech ID\n",
    "ga_id = 'thu82'\n",
    "# Requires a print() statement do not modify below print statement\n",
    "print(ga_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Z1gV3UlcWvD"
   },
   "source": [
    "# Q3.1 Data Import and Cleansing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VS44b2kcWvE"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Read in all the data. Replace the 'xxx' with the path to the data set. We've started this for you. \n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "data = pd.read_csv('./pulsar_stars.csv')\n",
    "#data.head()\n",
    "# -------------------------------\n",
    "\n",
    "# XXX\n",
    "# TODO: Separate out the x_data and y_data. We've started this for you.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "x_data = data.loc[:,data.columns !='y']\n",
    "#x_data.head()\n",
    "y_data = data.loc[:,'y']\n",
    "# -------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xuEypbCqcWvG"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Split 70% of the data into training and 30% into test sets. Call them x_train, x_test, y_train and y_test.\n",
    "# Use the train_test_split method in sklearn with the parameter 'shuffle' set to true and the 'random_state' \n",
    "# set to 614.\n",
    "# \n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.30, random_state=614, shuffle=True)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q09V5Ux5cWvI"
   },
   "source": [
    "# Q3.2 Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnHXBF1UcWvJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a LinearRegression classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McSbfk9WcWvL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracyis: 97.206258\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "y_train_pred = lr.predict(x_train)\n",
    "rounded = np.where(y_train_pred<0.5, 0, 1)\n",
    "train_acc = accuracy_score(y_train, rounded, normalize=True)*100\n",
    "print(\"The Accuracyis: %f\" % train_acc)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgySbn7xcWvN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracyis: 96.964618\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the testing set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "y_test_pred = lr.predict(x_test)\n",
    "rounded = np.where(y_test_pred<0.5, 0, 1)\n",
    "test_acc = accuracy_score(y_test, rounded, normalize=True)*100\n",
    "print(\"The Accuracyis: %f\" % test_acc)\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbqnCyHAcWvP"
   },
   "source": [
    "# Q3.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTtIFJW7cWvQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=614,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a RandomForestClassifier and train it.\n",
    "# Set 'random_state' to 614\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "rf =RandomForestClassifier(random_state=614)\n",
    "rf.fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWeNJLzqcWvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy: 99.680715\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "y_train_predicted= rf.predict(x_train)\n",
    "rounded = np.where(y_train_predicted<0.5, 0, 1)\n",
    "train_acc_rf= accuracy_score(y_train, rounded)*100\n",
    "print(\"The Accuracy: %f\" % train_acc_rf)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsMXeLyncWvU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy: 97.672253\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_test_predicted= rf.predict(x_test)\n",
    "rounded = np.where(y_test_predicted<0.5, 0, 1)\n",
    "test_acc_rf= accuracy_score(y_test,rounded)*100\n",
    "print(\"The Accuracy: %f\" % test_acc_rf)\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEkwb0M3cWvW"
   },
   "source": [
    "## Q3.3.1 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmjevLlPcWvW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36631348 0.05096543 0.25857456 0.11768744 0.05862141 0.03806286\n",
      " 0.05627799 0.05349682]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Determine the feature importance as evaluated by the Random Forest Classifier.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "rf_feat= rf.feature_importances_\n",
    "print(rf_feat)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XcRI7kUcWvY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "feature 0 (0.366313)\n",
      "feature 2 (0.258575)\n",
      "feature 3 (0.117687)\n",
      "feature 4 (0.058621)\n",
      "feature 6 (0.056278)\n",
      "feature 7 (0.053497)\n",
      "feature 1 (0.050965)\n",
      "feature 5 (0.038063)\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Sort them in the descending order and print the feature numbers[0 to ...].\n",
    "#       Hint: There is a direct function available in sklearn to achieve this. Also checkout argsort() function in Python.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "\n",
    "indices = np.argsort(rf_feat)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(x_train.shape[1]):\n",
    "    print(\"feature %d (%f)\" % (indices[f], rf_feat[indices[f]]))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AlCc_E3cWva"
   },
   "source": [
    "## Q3.3.2 Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3fjpmWLcWvb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [2, 8, 16], 'n_estimators': [4, 16, 256]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'n_estimators' and 'max_depth'.\n",
    "# 'n_estimators': [4, 16, 256]\n",
    "# 'max_depth': [2, 8, 16]\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "rf_params = {'n_estimators': [ 4, 16, 256 ], 'max_depth': [2, 8, 16]}\n",
    "tuned_rf = RandomForestClassifier()\n",
    "new_model = GridSearchCV(tuned_rf, rf_params)\n",
    "new_model.fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0OaHSCRcWvc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter after CV:{'max_depth': 16, 'n_estimators': 256}\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best params, using .best_params_\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "best_param = new_model.best_params_\n",
    "print(\"Best parameter after CV:\" +str(best_param))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyXkkZr9cWve"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best socre is: 0.980044699872286\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best score, using .best_score_.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "best_score = new_model.best_score_\n",
    "print(\"The best socre is: \" + str(best_score))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNeOPWIpcWvg"
   },
   "source": [
    "# Q3.4 Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CN3Wkw7zcWvh"
   },
   "source": [
    "## Q3.4.1 Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9msZXyImcWvh"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Pre-process the data to standardize it, otherwise the grid search will take much longer.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "#x_train_norm = normalize(x_train) #standard scaler?\n",
    "#x_test_norm = normalize(x_test)\n",
    "\n",
    "x_train_norm = StandardScaler().fit_transform(x_train) \n",
    "x_test_norm = StandardScaler().fit_transform(x_test)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqz1htxM9rLO"
   },
   "source": [
    "## Q3.4.2 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_nrOJdIcWvj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a SVC classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "svc = SVC() \n",
    "svc.fit(x_train_norm, y_train)\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U40EOPEecWvl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy: 98.020434\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "ytrain_pred_svc = svc.predict(x_train_norm)\n",
    "rounded = np.where(ytrain_pred_svc<0.5, 0, 1)\n",
    "train_acc_svc = accuracy_score(y_train,rounded)*100\n",
    "print(\"The Accuracy: %f\" % train_acc_svc)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_jidMDvcWvm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy: 97.616387\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "ytest_pred_svc = svc.predict(x_test_norm)\n",
    "rounded = np.where(ytest_pred_svc<0.5, 0, 1)\n",
    "test_acc_svc = accuracy_score(y_test,rounded)*100\n",
    "print(\"The Accuracy: %f\" % test_acc_svc)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89N3JURqcWvp"
   },
   "source": [
    "## Q3.4.3 Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufWB_j_-cWvq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.01, 0.1, 1.0], 'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'C' and 'kernel' (use rbf and linear).\n",
    "# 'kernel':('linear', 'rbf') \n",
    "# 'C':[0.01, 0.1, 1.0]\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "svc_params = {'C': [0.01, 0.1, 1.0], 'kernel': ['linear', 'rbf']}\n",
    "tuned_svc = SVC(gamma='auto')\n",
    "new_svc = GridSearchCV(tuned_svc, svc_params, return_train_score=True)\n",
    "new_svc.fit(x_train_norm, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYsFkceBcWvu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is:0.9793263090676884\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best score, using .best_score_.\n",
    "# Note: Set n_jobs=-1 and return_train_score=True\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "print(\"The best score is:\" +str(new_svc.best_score_))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_i1BM7zQcWvw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Calculate the training and test set accuracy values after hyperparameter tuning and standardization. \n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "C= (new_svc.best_params_.get('C'))\n",
    "kernel= (new_svc.best_params_.get('kernel'))\n",
    "opt_svc_model = SVC(C=C,kernel=kernel)\n",
    "opt_svc_model.fit(x_train,y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UzWph6Y9rLs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy: 97.972542\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "y_pred_train_svc_tune = opt_svc_model.predict(x_train)\n",
    "rounded = np.where(y_pred_train_svc_tune<0.5, 0, 1)\n",
    "train_acc_tune_svc = accuracy_score(y_train, rounded)*100\n",
    "print(\"The Accuracy: %f\" % train_acc_tune_svc)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSQXwaDn9rLw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy: 97.728119\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the test set) using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "y_pred_test_svc_tune = opt_svc_model.predict(x_test)\n",
    "rounded = np.where(y_pred_test_svc_tune<0.5, 0, 1)\n",
    "test_acc_tune_svc = accuracy_score(y_test, rounded)*100\n",
    "print(\"The Accuracy: %f\" % test_acc_tune_svc)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Io4IVbup9rL1"
   },
   "source": [
    "## Q3.4.4 Cross Validation Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kVfAqsbcWv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank Test Score: [5 6 3 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the rank test score for all hyperparameter values that you obtained in Q3.4.3. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "rank =  new_svc.cv_results_['rank_test_score']\n",
    "print(\"Rank Test Score:\", rank)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UrUu1DXcWv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Score: [0.97597382 0.96767241 0.9785281  0.97772989 0.97932631 0.97916667]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the mean testing score for all of hyperparameter values that you obtained in Q3.4.3. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "mean_test = new_svc.cv_results_['mean_test_score']\n",
    "print(\"Mean Test Score:\", mean_test)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2qDYMjgcWv5"
   },
   "source": [
    "# Q3.5 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-C9BuGsqcWv5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
       "    svd_solver='full', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Perform dimensionality reduction of the data using PCA.\n",
    "#       Set parameters n_component to 8 and svd_solver to 'full'. Keep other parameters at their default value.\n",
    "# XXX\n",
    "\n",
    "# NOTE: Use the full x data set for this section 'x_data'\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "pca = PCA(n_components=8, svd_solver = 'full')\n",
    "pca.fit(x_train)\n",
    "# You should see an output here of PCA(copy=True....)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZCJCtGhcWv7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.73068649e-01 7.70947157e-02 4.04656131e-02 5.95488462e-03\n",
      " 2.42361971e-03 9.50698595e-04 3.90491241e-05 2.76982242e-06]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get percentage of variance explained by each of the selected components\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "print(pca.explained_variance_ratio_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9nPDDyTcWv8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12093.64259684  3593.72829121  2603.6103879    998.77947434\n",
      "   637.18445368   399.07485002    80.87952298    21.54065458]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the singular values corresponding to each of the selected components.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "print(pca.singular_values_)\n",
    "# -------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw4q3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
